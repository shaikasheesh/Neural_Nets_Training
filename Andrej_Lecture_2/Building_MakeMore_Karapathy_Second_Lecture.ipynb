{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e31bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9a3263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter, attrgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff546b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt','r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6252eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98be1a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding min len of word in list of words\n",
    "min([len(w) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92a23412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding max len of word in list of words\n",
    "max([len(w) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7449d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = {}\n",
    "for w in words:\n",
    "    chs = ['<S'] + list(w) + ['E>']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        bigram = (ch1,ch2)\n",
    "        b[bigram] = b.get(bigram,0) + 1\n",
    "        #print(b)\n",
    "        #print(ch1,ch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cd43abf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('n', 'E>'), 6763),\n",
       " (('a', 'E>'), 6640),\n",
       " (('a', 'n'), 5438),\n",
       " (('<S', 'a'), 4410),\n",
       " (('e', 'E>'), 3983),\n",
       " (('a', 'r'), 3264),\n",
       " (('e', 'l'), 3248),\n",
       " (('r', 'i'), 3033),\n",
       " (('n', 'a'), 2977),\n",
       " (('<S', 'k'), 2963),\n",
       " (('l', 'e'), 2921),\n",
       " (('e', 'n'), 2675),\n",
       " (('l', 'a'), 2623),\n",
       " (('m', 'a'), 2590),\n",
       " (('<S', 'm'), 2538),\n",
       " (('a', 'l'), 2528),\n",
       " (('i', 'E>'), 2489),\n",
       " (('l', 'i'), 2480),\n",
       " (('i', 'a'), 2445),\n",
       " (('<S', 'j'), 2422),\n",
       " (('o', 'n'), 2411),\n",
       " (('h', 'E>'), 2409),\n",
       " (('r', 'a'), 2356),\n",
       " (('a', 'h'), 2332),\n",
       " (('h', 'a'), 2244),\n",
       " (('y', 'a'), 2143),\n",
       " (('i', 'n'), 2126),\n",
       " (('<S', 's'), 2055),\n",
       " (('a', 'y'), 2050),\n",
       " (('y', 'E>'), 2007),\n",
       " (('e', 'r'), 1958),\n",
       " (('n', 'n'), 1906),\n",
       " (('y', 'n'), 1826),\n",
       " (('k', 'a'), 1731),\n",
       " (('n', 'i'), 1725),\n",
       " (('r', 'e'), 1697),\n",
       " (('<S', 'd'), 1690),\n",
       " (('i', 'e'), 1653),\n",
       " (('a', 'i'), 1650),\n",
       " (('<S', 'r'), 1639),\n",
       " (('a', 'm'), 1634),\n",
       " (('l', 'y'), 1588),\n",
       " (('<S', 'l'), 1572),\n",
       " (('<S', 'c'), 1542),\n",
       " (('<S', 'e'), 1531),\n",
       " (('j', 'a'), 1473),\n",
       " (('r', 'E>'), 1377),\n",
       " (('n', 'e'), 1359),\n",
       " (('l', 'l'), 1345),\n",
       " (('i', 'l'), 1345),\n",
       " (('i', 's'), 1316),\n",
       " (('l', 'E>'), 1314),\n",
       " (('<S', 't'), 1308),\n",
       " (('<S', 'b'), 1306),\n",
       " (('d', 'a'), 1303),\n",
       " (('s', 'h'), 1285),\n",
       " (('d', 'e'), 1283),\n",
       " (('e', 'e'), 1271),\n",
       " (('m', 'i'), 1256),\n",
       " (('s', 'a'), 1201),\n",
       " (('s', 'E>'), 1169),\n",
       " (('<S', 'n'), 1146),\n",
       " (('a', 's'), 1118),\n",
       " (('y', 'l'), 1104),\n",
       " (('e', 'y'), 1070),\n",
       " (('o', 'r'), 1059),\n",
       " (('a', 'd'), 1042),\n",
       " (('t', 'a'), 1027),\n",
       " (('<S', 'z'), 929),\n",
       " (('v', 'i'), 911),\n",
       " (('k', 'e'), 895),\n",
       " (('s', 'e'), 884),\n",
       " (('<S', 'h'), 874),\n",
       " (('r', 'o'), 869),\n",
       " (('e', 's'), 861),\n",
       " (('z', 'a'), 860),\n",
       " (('o', 'E>'), 855),\n",
       " (('i', 'r'), 849),\n",
       " (('b', 'r'), 842),\n",
       " (('a', 'v'), 834),\n",
       " (('m', 'e'), 818),\n",
       " (('e', 'i'), 818),\n",
       " (('c', 'a'), 815),\n",
       " (('i', 'y'), 779),\n",
       " (('r', 'y'), 773),\n",
       " (('e', 'm'), 769),\n",
       " (('s', 't'), 765),\n",
       " (('h', 'i'), 729),\n",
       " (('t', 'e'), 716),\n",
       " (('n', 'd'), 704),\n",
       " (('l', 'o'), 692),\n",
       " (('a', 'e'), 692),\n",
       " (('a', 't'), 687),\n",
       " (('s', 'i'), 684),\n",
       " (('e', 'a'), 679),\n",
       " (('d', 'i'), 674),\n",
       " (('h', 'e'), 674),\n",
       " (('<S', 'g'), 669),\n",
       " (('t', 'o'), 667),\n",
       " (('c', 'h'), 664),\n",
       " (('b', 'e'), 655),\n",
       " (('t', 'h'), 647),\n",
       " (('v', 'a'), 642),\n",
       " (('o', 'l'), 619),\n",
       " (('<S', 'i'), 591),\n",
       " (('i', 'o'), 588),\n",
       " (('e', 't'), 580),\n",
       " (('v', 'e'), 568),\n",
       " (('a', 'k'), 568),\n",
       " (('a', 'a'), 556),\n",
       " (('c', 'e'), 551),\n",
       " (('a', 'b'), 541),\n",
       " (('i', 't'), 541),\n",
       " (('<S', 'y'), 535),\n",
       " (('t', 'i'), 532),\n",
       " (('s', 'o'), 531),\n",
       " (('m', 'E>'), 516),\n",
       " (('d', 'E>'), 516),\n",
       " (('<S', 'p'), 515),\n",
       " (('i', 'c'), 509),\n",
       " (('k', 'i'), 509),\n",
       " (('o', 's'), 504),\n",
       " (('n', 'o'), 496),\n",
       " (('t', 'E>'), 483),\n",
       " (('j', 'o'), 479),\n",
       " (('u', 's'), 474),\n",
       " (('a', 'c'), 470),\n",
       " (('n', 'y'), 465),\n",
       " (('e', 'v'), 463),\n",
       " (('s', 's'), 461),\n",
       " (('m', 'o'), 452),\n",
       " (('i', 'k'), 445),\n",
       " (('n', 't'), 443),\n",
       " (('i', 'd'), 440),\n",
       " (('j', 'e'), 440),\n",
       " (('a', 'z'), 435),\n",
       " (('i', 'g'), 428),\n",
       " (('i', 'm'), 427),\n",
       " (('r', 'r'), 425),\n",
       " (('d', 'r'), 424),\n",
       " (('<S', 'f'), 417),\n",
       " (('u', 'r'), 414),\n",
       " (('r', 'l'), 413),\n",
       " (('y', 's'), 401),\n",
       " (('<S', 'o'), 394),\n",
       " (('e', 'd'), 384),\n",
       " (('a', 'u'), 381),\n",
       " (('c', 'o'), 380),\n",
       " (('k', 'y'), 379),\n",
       " (('d', 'o'), 378),\n",
       " (('<S', 'v'), 376),\n",
       " (('t', 't'), 374),\n",
       " (('z', 'e'), 373),\n",
       " (('z', 'i'), 364),\n",
       " (('k', 'E>'), 363),\n",
       " (('g', 'h'), 360),\n",
       " (('t', 'r'), 352),\n",
       " (('k', 'o'), 344),\n",
       " (('t', 'y'), 341),\n",
       " (('g', 'e'), 334),\n",
       " (('g', 'a'), 330),\n",
       " (('l', 'u'), 324),\n",
       " (('b', 'a'), 321),\n",
       " (('d', 'y'), 317),\n",
       " (('c', 'k'), 316),\n",
       " (('<S', 'w'), 307),\n",
       " (('k', 'h'), 307),\n",
       " (('u', 'l'), 301),\n",
       " (('y', 'e'), 301),\n",
       " (('y', 'r'), 291),\n",
       " (('m', 'y'), 287),\n",
       " (('h', 'o'), 287),\n",
       " (('w', 'a'), 280),\n",
       " (('s', 'l'), 279),\n",
       " (('n', 's'), 278),\n",
       " (('i', 'z'), 277),\n",
       " (('u', 'n'), 275),\n",
       " (('o', 'u'), 275),\n",
       " (('n', 'g'), 273),\n",
       " (('y', 'd'), 272),\n",
       " (('c', 'i'), 271),\n",
       " (('y', 'o'), 271),\n",
       " (('i', 'v'), 269),\n",
       " (('e', 'o'), 269),\n",
       " (('o', 'm'), 261),\n",
       " (('r', 'u'), 252),\n",
       " (('f', 'a'), 242),\n",
       " (('b', 'i'), 217),\n",
       " (('s', 'y'), 215),\n",
       " (('n', 'c'), 213),\n",
       " (('h', 'y'), 213),\n",
       " (('p', 'a'), 209),\n",
       " (('r', 't'), 208),\n",
       " (('q', 'u'), 206),\n",
       " (('p', 'h'), 204),\n",
       " (('h', 'r'), 204),\n",
       " (('j', 'u'), 202),\n",
       " (('g', 'r'), 201),\n",
       " (('p', 'e'), 197),\n",
       " (('n', 'l'), 195),\n",
       " (('y', 'i'), 192),\n",
       " (('g', 'i'), 190),\n",
       " (('o', 'd'), 190),\n",
       " (('r', 's'), 190),\n",
       " (('r', 'd'), 187),\n",
       " (('h', 'l'), 185),\n",
       " (('s', 'u'), 185),\n",
       " (('a', 'x'), 182),\n",
       " (('e', 'z'), 181),\n",
       " (('e', 'k'), 178),\n",
       " (('o', 'v'), 176),\n",
       " (('a', 'j'), 175),\n",
       " (('o', 'h'), 171),\n",
       " (('u', 'e'), 169),\n",
       " (('m', 'm'), 168),\n",
       " (('a', 'g'), 168),\n",
       " (('h', 'u'), 166),\n",
       " (('x', 'E>'), 164),\n",
       " (('u', 'a'), 163),\n",
       " (('r', 'm'), 162),\n",
       " (('a', 'w'), 161),\n",
       " (('f', 'i'), 160),\n",
       " (('z', 'E>'), 160),\n",
       " (('u', 'E>'), 155),\n",
       " (('u', 'm'), 154),\n",
       " (('e', 'c'), 153),\n",
       " (('v', 'o'), 153),\n",
       " (('e', 'h'), 152),\n",
       " (('p', 'r'), 151),\n",
       " (('d', 'd'), 149),\n",
       " (('o', 'a'), 149),\n",
       " (('w', 'e'), 149),\n",
       " (('w', 'i'), 148),\n",
       " (('y', 'm'), 148),\n",
       " (('z', 'y'), 147),\n",
       " (('n', 'z'), 145),\n",
       " (('y', 'u'), 141),\n",
       " (('r', 'n'), 140),\n",
       " (('o', 'b'), 140),\n",
       " (('k', 'l'), 139),\n",
       " (('m', 'u'), 139),\n",
       " (('l', 'd'), 138),\n",
       " (('h', 'n'), 138),\n",
       " (('u', 'd'), 136),\n",
       " (('<S', 'x'), 134),\n",
       " (('t', 'l'), 134),\n",
       " (('a', 'f'), 134),\n",
       " (('o', 'e'), 132),\n",
       " (('e', 'x'), 132),\n",
       " (('e', 'g'), 125),\n",
       " (('f', 'e'), 123),\n",
       " (('z', 'l'), 123),\n",
       " (('u', 'i'), 121),\n",
       " (('v', 'y'), 121),\n",
       " (('e', 'b'), 121),\n",
       " (('r', 'h'), 121),\n",
       " (('j', 'i'), 119),\n",
       " (('o', 't'), 118),\n",
       " (('d', 'h'), 118),\n",
       " (('h', 'm'), 117),\n",
       " (('c', 'l'), 116),\n",
       " (('o', 'o'), 115),\n",
       " (('y', 'c'), 115),\n",
       " (('o', 'w'), 114),\n",
       " (('o', 'c'), 114),\n",
       " (('f', 'r'), 114),\n",
       " (('b', 'E>'), 114),\n",
       " (('m', 'b'), 112),\n",
       " (('z', 'o'), 110),\n",
       " (('i', 'b'), 110),\n",
       " (('i', 'u'), 109),\n",
       " (('k', 'r'), 109),\n",
       " (('g', 'E>'), 108),\n",
       " (('y', 'v'), 106),\n",
       " (('t', 'z'), 105),\n",
       " (('b', 'o'), 105),\n",
       " (('c', 'y'), 104),\n",
       " (('y', 't'), 104),\n",
       " (('u', 'b'), 103),\n",
       " (('u', 'c'), 103),\n",
       " (('x', 'a'), 103),\n",
       " (('b', 'l'), 103),\n",
       " (('o', 'y'), 103),\n",
       " (('x', 'i'), 102),\n",
       " (('i', 'f'), 101),\n",
       " (('r', 'c'), 99),\n",
       " (('c', 'E>'), 97),\n",
       " (('m', 'r'), 97),\n",
       " (('n', 'u'), 96),\n",
       " (('o', 'p'), 95),\n",
       " (('i', 'h'), 95),\n",
       " (('k', 's'), 95),\n",
       " (('l', 's'), 94),\n",
       " (('u', 'k'), 93),\n",
       " (('<S', 'q'), 92),\n",
       " (('d', 'u'), 92),\n",
       " (('s', 'm'), 90),\n",
       " (('r', 'k'), 90),\n",
       " (('i', 'x'), 89),\n",
       " (('v', 'E>'), 88),\n",
       " (('y', 'k'), 86),\n",
       " (('u', 'w'), 86),\n",
       " (('g', 'u'), 85),\n",
       " (('b', 'y'), 83),\n",
       " (('e', 'p'), 83),\n",
       " (('g', 'o'), 83),\n",
       " (('s', 'k'), 82),\n",
       " (('u', 't'), 82),\n",
       " (('a', 'p'), 82),\n",
       " (('e', 'f'), 82),\n",
       " (('i', 'i'), 82),\n",
       " (('r', 'v'), 80),\n",
       " (('f', 'E>'), 80),\n",
       " (('t', 'u'), 78),\n",
       " (('y', 'z'), 78),\n",
       " (('<S', 'u'), 78),\n",
       " (('l', 't'), 77),\n",
       " (('r', 'g'), 76),\n",
       " (('c', 'r'), 76),\n",
       " (('i', 'j'), 76),\n",
       " (('w', 'y'), 73),\n",
       " (('z', 'u'), 73),\n",
       " (('l', 'v'), 72),\n",
       " (('h', 't'), 71),\n",
       " (('j', 'E>'), 71),\n",
       " (('x', 't'), 70),\n",
       " (('o', 'i'), 69),\n",
       " (('e', 'u'), 69),\n",
       " (('o', 'k'), 68),\n",
       " (('b', 'd'), 65),\n",
       " (('a', 'o'), 63),\n",
       " (('p', 'i'), 61),\n",
       " (('s', 'c'), 60),\n",
       " (('d', 'l'), 60),\n",
       " (('l', 'm'), 60),\n",
       " (('a', 'q'), 60),\n",
       " (('f', 'o'), 60),\n",
       " (('p', 'o'), 59),\n",
       " (('n', 'k'), 58),\n",
       " (('w', 'n'), 58),\n",
       " (('u', 'h'), 58),\n",
       " (('e', 'j'), 55),\n",
       " (('n', 'v'), 55),\n",
       " (('s', 'r'), 55),\n",
       " (('o', 'z'), 54),\n",
       " (('i', 'p'), 53),\n",
       " (('l', 'b'), 52),\n",
       " (('i', 'q'), 52),\n",
       " (('w', 'E>'), 51),\n",
       " (('m', 'c'), 51),\n",
       " (('s', 'p'), 51),\n",
       " (('e', 'w'), 50),\n",
       " (('k', 'u'), 50),\n",
       " (('v', 'r'), 48),\n",
       " (('u', 'g'), 47),\n",
       " (('o', 'x'), 45),\n",
       " (('u', 'z'), 45),\n",
       " (('z', 'z'), 45),\n",
       " (('j', 'h'), 45),\n",
       " (('b', 'u'), 45),\n",
       " (('o', 'g'), 44),\n",
       " (('n', 'r'), 44),\n",
       " (('f', 'f'), 44),\n",
       " (('n', 'j'), 44),\n",
       " (('z', 'h'), 43),\n",
       " (('c', 'c'), 42),\n",
       " (('r', 'b'), 41),\n",
       " (('x', 'o'), 41),\n",
       " (('b', 'h'), 41),\n",
       " (('p', 'p'), 39),\n",
       " (('x', 'l'), 39),\n",
       " (('h', 'v'), 39),\n",
       " (('b', 'b'), 38),\n",
       " (('m', 'p'), 38),\n",
       " (('x', 'x'), 38),\n",
       " (('u', 'v'), 37),\n",
       " (('x', 'e'), 36),\n",
       " (('w', 'o'), 36),\n",
       " (('c', 't'), 35),\n",
       " (('z', 'm'), 35),\n",
       " (('t', 's'), 35),\n",
       " (('m', 's'), 35),\n",
       " (('c', 'u'), 35),\n",
       " (('o', 'f'), 34),\n",
       " (('u', 'x'), 34),\n",
       " (('k', 'w'), 34),\n",
       " (('p', 'E>'), 33),\n",
       " (('g', 'l'), 32),\n",
       " (('z', 'r'), 32),\n",
       " (('d', 'n'), 31),\n",
       " (('g', 't'), 31),\n",
       " (('g', 'y'), 31),\n",
       " (('h', 's'), 31),\n",
       " (('x', 's'), 31),\n",
       " (('g', 's'), 30),\n",
       " (('x', 'y'), 30),\n",
       " (('y', 'g'), 30),\n",
       " (('d', 'm'), 30),\n",
       " (('d', 's'), 29),\n",
       " (('h', 'k'), 29),\n",
       " (('y', 'x'), 28),\n",
       " (('q', 'E>'), 28),\n",
       " (('g', 'n'), 27),\n",
       " (('y', 'b'), 27),\n",
       " (('g', 'w'), 26),\n",
       " (('n', 'h'), 26),\n",
       " (('k', 'n'), 26),\n",
       " (('g', 'g'), 25),\n",
       " (('d', 'g'), 25),\n",
       " (('l', 'c'), 25),\n",
       " (('r', 'j'), 25),\n",
       " (('w', 'u'), 25),\n",
       " (('l', 'k'), 24),\n",
       " (('m', 'd'), 24),\n",
       " (('s', 'w'), 24),\n",
       " (('s', 'n'), 24),\n",
       " (('h', 'd'), 24),\n",
       " (('w', 'h'), 23),\n",
       " (('y', 'j'), 23),\n",
       " (('y', 'y'), 23),\n",
       " (('r', 'z'), 23),\n",
       " (('d', 'w'), 23),\n",
       " (('w', 'r'), 22),\n",
       " (('t', 'n'), 22),\n",
       " (('l', 'f'), 22),\n",
       " (('y', 'h'), 22),\n",
       " (('r', 'w'), 21),\n",
       " (('s', 'b'), 21),\n",
       " (('m', 'n'), 20),\n",
       " (('f', 'l'), 20),\n",
       " (('w', 's'), 20),\n",
       " (('k', 'k'), 20),\n",
       " (('h', 'z'), 20),\n",
       " (('g', 'd'), 19),\n",
       " (('l', 'h'), 19),\n",
       " (('n', 'm'), 19),\n",
       " (('x', 'z'), 19),\n",
       " (('u', 'f'), 19),\n",
       " (('f', 't'), 18),\n",
       " (('l', 'r'), 18),\n",
       " (('p', 't'), 17),\n",
       " (('t', 'c'), 17),\n",
       " (('k', 't'), 17),\n",
       " (('d', 'v'), 17),\n",
       " (('u', 'p'), 16),\n",
       " (('p', 'l'), 16),\n",
       " (('l', 'w'), 16),\n",
       " (('p', 's'), 16),\n",
       " (('o', 'j'), 16),\n",
       " (('r', 'q'), 16),\n",
       " (('y', 'p'), 15),\n",
       " (('l', 'p'), 15),\n",
       " (('t', 'v'), 15),\n",
       " (('r', 'p'), 14),\n",
       " (('l', 'n'), 14),\n",
       " (('e', 'q'), 14),\n",
       " (('f', 'y'), 14),\n",
       " (('s', 'v'), 14),\n",
       " (('u', 'j'), 14),\n",
       " (('v', 'l'), 14),\n",
       " (('q', 'a'), 13),\n",
       " (('u', 'y'), 13),\n",
       " (('q', 'i'), 13),\n",
       " (('w', 'l'), 13),\n",
       " (('p', 'y'), 12),\n",
       " (('y', 'f'), 12),\n",
       " (('c', 'q'), 11),\n",
       " (('j', 'r'), 11),\n",
       " (('n', 'w'), 11),\n",
       " (('n', 'f'), 11),\n",
       " (('t', 'w'), 11),\n",
       " (('m', 'z'), 11),\n",
       " (('u', 'o'), 10),\n",
       " (('f', 'u'), 10),\n",
       " (('l', 'z'), 10),\n",
       " (('h', 'w'), 10),\n",
       " (('u', 'q'), 10),\n",
       " (('j', 'y'), 10),\n",
       " (('s', 'z'), 10),\n",
       " (('s', 'd'), 9),\n",
       " (('j', 'l'), 9),\n",
       " (('d', 'j'), 9),\n",
       " (('k', 'm'), 9),\n",
       " (('r', 'f'), 9),\n",
       " (('h', 'j'), 9),\n",
       " (('v', 'n'), 8),\n",
       " (('n', 'b'), 8),\n",
       " (('i', 'w'), 8),\n",
       " (('h', 'b'), 8),\n",
       " (('b', 's'), 8),\n",
       " (('w', 't'), 8),\n",
       " (('w', 'd'), 8),\n",
       " (('v', 'v'), 7),\n",
       " (('v', 'u'), 7),\n",
       " (('j', 's'), 7),\n",
       " (('m', 'j'), 7),\n",
       " (('f', 's'), 6),\n",
       " (('l', 'g'), 6),\n",
       " (('l', 'j'), 6),\n",
       " (('j', 'w'), 6),\n",
       " (('n', 'x'), 6),\n",
       " (('y', 'q'), 6),\n",
       " (('w', 'k'), 6),\n",
       " (('g', 'm'), 6),\n",
       " (('x', 'u'), 5),\n",
       " (('m', 'h'), 5),\n",
       " (('m', 'l'), 5),\n",
       " (('j', 'm'), 5),\n",
       " (('c', 's'), 5),\n",
       " (('j', 'v'), 5),\n",
       " (('n', 'p'), 5),\n",
       " (('d', 'f'), 5),\n",
       " (('x', 'd'), 5),\n",
       " (('z', 'b'), 4),\n",
       " (('f', 'n'), 4),\n",
       " (('x', 'c'), 4),\n",
       " (('m', 't'), 4),\n",
       " (('t', 'm'), 4),\n",
       " (('z', 'n'), 4),\n",
       " (('z', 't'), 4),\n",
       " (('p', 'u'), 4),\n",
       " (('c', 'z'), 4),\n",
       " (('b', 'n'), 4),\n",
       " (('z', 's'), 4),\n",
       " (('f', 'w'), 4),\n",
       " (('d', 't'), 4),\n",
       " (('j', 'd'), 4),\n",
       " (('j', 'c'), 4),\n",
       " (('y', 'w'), 4),\n",
       " (('v', 'k'), 3),\n",
       " (('x', 'w'), 3),\n",
       " (('t', 'j'), 3),\n",
       " (('c', 'j'), 3),\n",
       " (('q', 'w'), 3),\n",
       " (('g', 'b'), 3),\n",
       " (('o', 'q'), 3),\n",
       " (('r', 'x'), 3),\n",
       " (('d', 'c'), 3),\n",
       " (('g', 'j'), 3),\n",
       " (('x', 'f'), 3),\n",
       " (('z', 'w'), 3),\n",
       " (('d', 'k'), 3),\n",
       " (('u', 'u'), 3),\n",
       " (('m', 'v'), 3),\n",
       " (('c', 'x'), 3),\n",
       " (('l', 'q'), 3),\n",
       " (('p', 'b'), 2),\n",
       " (('t', 'g'), 2),\n",
       " (('q', 's'), 2),\n",
       " (('t', 'x'), 2),\n",
       " (('f', 'k'), 2),\n",
       " (('b', 't'), 2),\n",
       " (('j', 'n'), 2),\n",
       " (('k', 'c'), 2),\n",
       " (('z', 'k'), 2),\n",
       " (('s', 'j'), 2),\n",
       " (('s', 'f'), 2),\n",
       " (('z', 'j'), 2),\n",
       " (('n', 'q'), 2),\n",
       " (('f', 'z'), 2),\n",
       " (('h', 'g'), 2),\n",
       " (('w', 'w'), 2),\n",
       " (('k', 'j'), 2),\n",
       " (('j', 'k'), 2),\n",
       " (('w', 'm'), 2),\n",
       " (('z', 'c'), 2),\n",
       " (('z', 'v'), 2),\n",
       " (('w', 'f'), 2),\n",
       " (('q', 'm'), 2),\n",
       " (('k', 'z'), 2),\n",
       " (('j', 'j'), 2),\n",
       " (('z', 'p'), 2),\n",
       " (('j', 't'), 2),\n",
       " (('k', 'b'), 2),\n",
       " (('m', 'w'), 2),\n",
       " (('h', 'f'), 2),\n",
       " (('c', 'g'), 2),\n",
       " (('t', 'f'), 2),\n",
       " (('h', 'c'), 2),\n",
       " (('q', 'o'), 2),\n",
       " (('k', 'd'), 2),\n",
       " (('k', 'v'), 2),\n",
       " (('s', 'g'), 2),\n",
       " (('z', 'd'), 2),\n",
       " (('q', 'r'), 1),\n",
       " (('d', 'z'), 1),\n",
       " (('p', 'j'), 1),\n",
       " (('q', 'l'), 1),\n",
       " (('p', 'f'), 1),\n",
       " (('q', 'e'), 1),\n",
       " (('b', 'c'), 1),\n",
       " (('c', 'd'), 1),\n",
       " (('m', 'f'), 1),\n",
       " (('p', 'n'), 1),\n",
       " (('w', 'b'), 1),\n",
       " (('p', 'c'), 1),\n",
       " (('h', 'p'), 1),\n",
       " (('f', 'h'), 1),\n",
       " (('b', 'j'), 1),\n",
       " (('f', 'g'), 1),\n",
       " (('z', 'g'), 1),\n",
       " (('c', 'p'), 1),\n",
       " (('p', 'k'), 1),\n",
       " (('p', 'm'), 1),\n",
       " (('x', 'n'), 1),\n",
       " (('s', 'q'), 1),\n",
       " (('k', 'f'), 1),\n",
       " (('m', 'k'), 1),\n",
       " (('x', 'h'), 1),\n",
       " (('g', 'f'), 1),\n",
       " (('v', 'b'), 1),\n",
       " (('j', 'p'), 1),\n",
       " (('g', 'z'), 1),\n",
       " (('v', 'd'), 1),\n",
       " (('d', 'b'), 1),\n",
       " (('v', 'h'), 1),\n",
       " (('h', 'h'), 1),\n",
       " (('g', 'v'), 1),\n",
       " (('d', 'q'), 1),\n",
       " (('x', 'b'), 1),\n",
       " (('w', 'z'), 1),\n",
       " (('h', 'q'), 1),\n",
       " (('j', 'b'), 1),\n",
       " (('x', 'm'), 1),\n",
       " (('w', 'g'), 1),\n",
       " (('t', 'b'), 1),\n",
       " (('z', 'x'), 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(b.items(),key = itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e709a78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets keep this in 2d array\n",
    "# rows are 1st ch and col are 2nd ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2f99db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27,27), dtype = torch.int32) # 26 alphabets plus 2 special start and end tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe50b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(set(''.join(words)))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b674c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        N[ix1,ix2] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "047550aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# plt.figure(figsize=(16,16))\n",
    "# plt.imshow(N, cmap='Blues')\n",
    "# for i in range(28):\n",
    "#     for j in range(28):\n",
    "#         chstr = itos[i] + itos[j]\n",
    "#         plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
    "#         plt.text(j, i, N[i, j].item(), ha=\"center\", va=\"top\", color='gray')\n",
    "# plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f2376c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 4410, 1306, 1542, 1690, 1531,  417,  669,  874,  591, 2422, 2963,\n",
       "        1572, 2538, 1146,  394,  515,   92, 1639, 2055, 1308,   78,  376,  307,\n",
       "         134,  535,  929], dtype=torch.int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21a1ccac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0408)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0,2] / N[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cdaa982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
       "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
       "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = N[0].float()\n",
    "p = p / p.sum() #normalize\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6b033a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46f1dd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "itos[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0fb38a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = (N+1).float()\n",
    "P = P/ P.sum(axis = 1, keepdim = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14a3ee7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mor\n",
      "axx\n",
      "minaymoryles\n",
      "kondlaisah\n",
      "anchshizarie\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "#         p = N[ix].float()\n",
    "#         p = p/p.sum()\n",
    "        p = P[ix]\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        if ix == 0:\n",
    "            break\n",
    "        out.append(itos[ix])\n",
    "\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bf4afe9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".a : 0.14 -1.98\n",
      "as : 0.03 -3.41\n",
      "sh : 0.16 -1.84\n",
      "he : 0.09 -2.43\n",
      "ee : 0.06 -2.78\n",
      "es : 0.04 -3.17\n",
      "sh : 0.16 -1.84\n",
      "hj : 0.00 -6.64\n",
      "jq : 0.00 -7.98\n",
      "q. : 0.10 -2.33\n",
      "log_likely_hood=tensor(-34.4082)\n",
      "nll=tensor(34.4082)\n",
      "normalized nll: 3.4408175945281982\n"
     ]
    }
   ],
   "source": [
    "log_likely_hood = 0.0\n",
    "n = 0\n",
    "for w in [\"asheeshjq\"]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        p = P[ix1,ix2]\n",
    "        logp = torch.log(p)\n",
    "        log_likely_hood += logp\n",
    "        n+=1\n",
    "        print(f'{ch1}{ch2} : {p:.2f} {logp: .2f}')\n",
    "print(f'{log_likely_hood=}')\n",
    "nll = -log_likely_hood\n",
    "print(f'{nll=}')\n",
    "print(f'normalized nll: {nll/n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4905c1",
   "metadata": {},
   "source": [
    "**Approach 2 Using NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fcc623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating training data set of bigrams(x,y)\n",
    "\n",
    "xs, ys = [] , []\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4af26153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "664b90db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7ccb62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding the values\n",
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=27).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9311c192",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cc4a406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7d456f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e95e61a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2993, -0.9032,  1.1147,  0.8408,  0.9417,  0.1955,  0.6066, -0.8068,\n",
       "         -0.9951, -0.7316,  0.1055, -0.1907,  0.2367,  0.9110, -0.0196,  0.5596,\n",
       "          1.0089,  0.2613,  0.4686, -0.7418, -1.4561, -0.1257,  1.8790,  1.8538,\n",
       "         -0.1056, -1.2839, -0.7695],\n",
       "        [ 0.6965,  1.3609,  0.5710, -1.1756, -0.2038,  0.7772, -1.1281,  1.4317,\n",
       "         -0.0371, -0.5092, -0.9179,  1.6242, -1.0693,  2.7455, -0.3422,  0.0594,\n",
       "         -0.2524, -1.1267,  0.9537,  0.5177,  0.0783, -0.9880,  0.9356,  1.7065,\n",
       "          1.0721,  0.0322, -0.1065],\n",
       "        [ 0.2553,  0.0682,  0.1819,  0.5261, -0.9319, -0.0367, -0.9463,  1.0085,\n",
       "         -2.8253,  1.5701,  1.0760,  0.4798, -0.2380, -0.3560, -1.3579, -0.2161,\n",
       "          0.2742,  0.7012, -1.0731, -3.1951,  0.4655, -0.3705, -2.3923,  0.5639,\n",
       "         -0.7568,  0.7133,  1.6138],\n",
       "        [ 0.2553,  0.0682,  0.1819,  0.5261, -0.9319, -0.0367, -0.9463,  1.0085,\n",
       "         -2.8253,  1.5701,  1.0760,  0.4798, -0.2380, -0.3560, -1.3579, -0.2161,\n",
       "          0.2742,  0.7012, -1.0731, -3.1951,  0.4655, -0.3705, -2.3923,  0.5639,\n",
       "         -0.7568,  0.7133,  1.6138],\n",
       "        [ 0.8754, -0.4230, -0.3947, -0.1867, -0.9262,  0.4460,  0.4485, -1.4833,\n",
       "         -0.0470, -1.1221, -2.3240, -0.1400,  0.7423, -2.0642, -0.1194,  1.3964,\n",
       "          0.8293,  0.2456, -1.0979,  0.2164, -0.5755, -0.1457, -0.5146, -0.9155,\n",
       "          0.7124, -0.8558, -0.5219]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build a single neuron\n",
    "\n",
    "W = torch.randn((27,27))\n",
    "\n",
    "xenc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17f32c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = xenc @ W # log-counts\n",
    "counts = logits.exp() #equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52fafc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd77d014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0305, 0.0092, 0.0689, 0.0524, 0.0579, 0.0275, 0.0414, 0.0101, 0.0084,\n",
       "        0.0109, 0.0251, 0.0187, 0.0286, 0.0562, 0.0222, 0.0395, 0.0620, 0.0293,\n",
       "        0.0361, 0.0108, 0.0053, 0.0199, 0.1479, 0.1443, 0.0203, 0.0063, 0.0105])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d866540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "183eac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward pass\n",
    "xenc = F.one_hot(xs, num_classes=27).float() #encode\n",
    "logits = xenc @ W # log-counts\n",
    "counts = logits.exp() #equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75897c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "bigram example 1: .e (indexes 0,5)\n",
      "input to the neural net: 0\n",
      "output probabilities from the neural net: tensor([0.0607, 0.0100, 0.0123, 0.0042, 0.0168, 0.0123, 0.0027, 0.0232, 0.0137,\n",
      "        0.0313, 0.0079, 0.0278, 0.0091, 0.0082, 0.0500, 0.2378, 0.0603, 0.0025,\n",
      "        0.0249, 0.0055, 0.0339, 0.0109, 0.0029, 0.0198, 0.0118, 0.1537, 0.1459])\n",
      "label (actual next character): 5\n",
      "probability assigned by the net to the the correct character: 0.01228625513613224\n",
      "log likelihood: -4.399273872375488\n",
      "negative log likelihood: 4.399273872375488\n",
      "--------\n",
      "bigram example 2: em (indexes 5,13)\n",
      "input to the neural net: 5\n",
      "output probabilities from the neural net: tensor([0.0290, 0.0796, 0.0248, 0.0521, 0.1989, 0.0289, 0.0094, 0.0335, 0.0097,\n",
      "        0.0301, 0.0702, 0.0228, 0.0115, 0.0181, 0.0108, 0.0315, 0.0291, 0.0045,\n",
      "        0.0916, 0.0215, 0.0486, 0.0300, 0.0501, 0.0027, 0.0118, 0.0022, 0.0472])\n",
      "label (actual next character): 13\n",
      "probability assigned by the net to the the correct character: 0.018050700426101685\n",
      "log likelihood: -4.014570713043213\n",
      "negative log likelihood: 4.014570713043213\n",
      "--------\n",
      "bigram example 3: mm (indexes 13,13)\n",
      "input to the neural net: 13\n",
      "output probabilities from the neural net: tensor([0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
      "        0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
      "        0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126])\n",
      "label (actual next character): 13\n",
      "probability assigned by the net to the the correct character: 0.026691533625125885\n",
      "log likelihood: -3.623408794403076\n",
      "negative log likelihood: 3.623408794403076\n",
      "--------\n",
      "bigram example 4: ma (indexes 13,1)\n",
      "input to the neural net: 13\n",
      "output probabilities from the neural net: tensor([0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
      "        0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
      "        0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126])\n",
      "label (actual next character): 1\n",
      "probability assigned by the net to the the correct character: 0.07367686182260513\n",
      "log likelihood: -2.6080665588378906\n",
      "negative log likelihood: 2.6080665588378906\n",
      "--------\n",
      "bigram example 5: a. (indexes 1,0)\n",
      "input to the neural net: 1\n",
      "output probabilities from the neural net: tensor([0.0150, 0.0086, 0.0396, 0.0100, 0.0606, 0.0308, 0.1084, 0.0131, 0.0125,\n",
      "        0.0048, 0.1024, 0.0086, 0.0988, 0.0112, 0.0232, 0.0207, 0.0408, 0.0078,\n",
      "        0.0899, 0.0531, 0.0463, 0.0309, 0.0051, 0.0329, 0.0654, 0.0503, 0.0091])\n",
      "label (actual next character): 0\n",
      "probability assigned by the net to the the correct character: 0.014977526850998402\n",
      "log likelihood: -4.201204299926758\n",
      "negative log likelihood: 4.201204299926758\n",
      "=========\n",
      "average negative log likelihood, i.e. loss = 3.7693049907684326\n"
     ]
    }
   ],
   "source": [
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "  # i-th bigram:\n",
    "  x = xs[i].item() # input character index\n",
    "  y = ys[i].item() # label character index\n",
    "  print('--------')\n",
    "  print(f'bigram example {i+1}: {itos[x]}{itos[y]} (indexes {x},{y})')\n",
    "  print('input to the neural net:', x)\n",
    "  print('output probabilities from the neural net:', probs[i])\n",
    "  print('label (actual next character):', y)\n",
    "  p = probs[i, y]\n",
    "  print('probability assigned by the net to the the correct character:', p.item())\n",
    "  logp = torch.log(p)\n",
    "  print('log likelihood:', logp.item())\n",
    "  nll = -logp\n",
    "  print('negative log likelihood:', nll.item())\n",
    "  nlls[i] = nll\n",
    "\n",
    "print('=========')\n",
    "print('average negative log likelihood, i.e. loss =', nlls.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f96a6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bec4f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cd583fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6693, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass\n",
    "xenc = F.one_hot(xs, num_classes=27).float() #encode\n",
    "logits = xenc @ W # log-counts\n",
    "counts = logits.exp() #equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims = True)\n",
    "ypred = probs[torch.arange(5),ys] #these are the predictions for range in 5 indices and ys \n",
    "loss = -ypred.log().mean() #negative log likelihood is the loss\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9331b3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backward pass\n",
    "W.grad = None\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71f3a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "W.data += -0.1*W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "525a1539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearranging everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ecbe43d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples 228146\n"
     ]
    }
   ],
   "source": [
    "#creating training data set of bigrams(x,y)\n",
    "xs, ys = [] , []\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print(\"number of examples\", num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "75148a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.758953332901001\n",
      "3.371100664138794\n",
      "3.154043197631836\n",
      "3.020373582839966\n",
      "2.927711248397827\n",
      "2.8604023456573486\n",
      "2.8097290992736816\n",
      "2.7701022624969482\n",
      "2.7380728721618652\n",
      "2.711496353149414\n",
      "2.6890029907226562\n",
      "2.6696884632110596\n",
      "2.6529300212860107\n",
      "2.638277292251587\n",
      "2.6253881454467773\n",
      "2.613990545272827\n",
      "2.60386323928833\n",
      "2.5948216915130615\n",
      "2.5867116451263428\n",
      "2.579403877258301\n",
      "2.572789192199707\n",
      "2.5667762756347656\n",
      "2.5612878799438477\n",
      "2.5562589168548584\n",
      "2.551633834838867\n",
      "2.547366142272949\n",
      "2.543415069580078\n",
      "2.5397486686706543\n",
      "2.5363364219665527\n",
      "2.5331544876098633\n",
      "2.5301806926727295\n",
      "2.5273969173431396\n",
      "2.5247862339019775\n",
      "2.522334575653076\n",
      "2.520028829574585\n",
      "2.517857789993286\n",
      "2.515810966491699\n",
      "2.513878345489502\n",
      "2.512052059173584\n",
      "2.510324001312256\n",
      "2.5086867809295654\n",
      "2.5071346759796143\n",
      "2.5056614875793457\n",
      "2.5042612552642822\n",
      "2.502929210662842\n",
      "2.5016613006591797\n",
      "2.5004520416259766\n",
      "2.4992988109588623\n",
      "2.498197317123413\n",
      "2.497144937515259\n"
     ]
    }
   ],
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad = True)\n",
    "\n",
    "for i in range(50):\n",
    "    #forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=27).float() #encode\n",
    "    logits = xenc @ W # log-counts\n",
    "    counts = logits.exp() #equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims = True)\n",
    "    ypred = probs[torch.arange(num),ys] #these are the predictions for range in 5 indices and ys \n",
    "    loss = -ypred.log().mean() #negative log likelihood is the loss\n",
    "    print(loss.item())\n",
    "    #backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    #updating weights using grads\n",
    "    W.data += -50*W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1dd3dffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mor\n",
      "axx\n",
      "minaymoryles\n",
      "kondmaisah\n",
      "anchthizarie\n"
     ]
    }
   ],
   "source": [
    "#sampling from neural net\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "#         p = N[ix].float()\n",
    "#         p = p/p.sum()\n",
    "#         p = P[ix]\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float() #encode\n",
    "        logits = xenc @ W # log-counts\n",
    "        counts = logits.exp() #equivalent to N\n",
    "        probs = counts / counts.sum(1, keepdims = True)\n",
    "        ix = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "        if ix == 0:\n",
    "            break\n",
    "        out.append(itos[ix])\n",
    "\n",
    "    print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
